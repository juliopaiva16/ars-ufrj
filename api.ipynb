{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instala√ß√£o dos pacotes necess√°rios\n",
    "\n",
    "Pandas: Biblioteca para manipula√ß√£o e an√°lise de dados\n",
    "PyArrow: Biblioteca para leitura e escrita de arquivos parquet\n",
    "Spotipy: Biblioteca para acesso a API do Spotify\n",
    "\n",
    "Use o comando abaixo para instalar os pacotes necess√°rios:\n",
    "```bash\n",
    "$ pip install pandas pyarrow spotipy\n",
    "```\n",
    "\n",
    "Ou instale as depend√™ncias diretamente do arquivo `requirements.txt`:\n",
    "```bash\n",
    "$ pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### Configura√ß√£o da API do Spotify com um .env\n",
    "\n",
    "Para acessar a API do Spotify √© necess√°rio criar um aplicativo no [Spotify for Developers](https://developer.spotify.com/dashboard/applications) e obter as credenciais de acesso.\n",
    "\n",
    "Crie um arquivo `.env` na raiz do projeto e adicione as seguintes vari√°veis de ambiente:\n",
    "```bash\n",
    "SPOTIPY_CLIENT_ID=seu_client_id\n",
    "SPOTIPY_CLIENT_SECRET=sua_client_secret\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_vars = {}\n",
    "\n",
    "# Le o arquivo .env\n",
    "with open('.env') as f:\n",
    "    env_vars = dict(\n",
    "        tuple(line.replace('\"', '').replace(\"'\", '').strip().split('=', 1)) for line in f\n",
    "    )\n",
    "\n",
    "# Cria o objeto de autentica√ß√£o\n",
    "client_credentials_manager = SpotifyClientCredentials(\n",
    "    client_id=env_vars['SPOTIPY_CLIENT_ID'],\n",
    "    client_secret=env_vars['SPOTIPY_CLIENT_SECRET']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist encontrada: CEP 20.000\n",
      "Obtendo m√∫sicas da playlist: 6JmtTvFjLMqwuw66DjdmdC\n",
      "M√∫sicas encontradas: 0\n",
      "-------------------------------------------------------\n",
      "Playlist encontrada: Underground 90 e 00\n",
      "Obtendo m√∫sicas da playlist: 0ssNBFYEvCHITWiE5GC4EG\n",
      "M√∫sicas encontradas: 0\n",
      "-------------------------------------------------------\n",
      "Playlist encontrada: UNDERGROUND CARIOCA üåêüìà\n",
      "Obtendo m√∫sicas da playlist: 2vXSVAsdyzPSiCiPb5EUxt\n",
      "M√∫sicas encontradas: 0\n",
      "-------------------------------------------------------\n",
      "Playlist encontrada: Underground Anos 90/2000\n",
      "Obtendo m√∫sicas da playlist: 17zzqYemdM2H5YVkuYRprQ\n",
      "M√∫sicas encontradas: 3\n",
      "-------------------------------------------------------\n",
      "Playlist encontrada: ELAM ANOS 90/2000\n",
      "Obtendo m√∫sicas da playlist: 33y3y1dssJsmq7TwAT4fd5\n",
      "M√∫sicas encontradas: 0\n",
      "-------------------------------------------------------\n",
      "Playlists encontradas: 5\n",
      "Musicas encontradas: 3\n"
     ]
    }
   ],
   "source": [
    "# Configurando as credenciais do cliente\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "# Fun√ß√£o para obter as 100 playlists mais populares de m√∫sica independente do Brasil\n",
    "def get_playlists(query = '', n = 1, offset = 50, market = 'BR'):\n",
    "    all_tracks = 0\n",
    "    all_playlists = []\n",
    "    for i in range(n):\n",
    "        try:\n",
    "            playlists = sp.search(query, limit=offset, offset=i*offset, type='playlist', market = market)\n",
    "            # Printando o nome das playlists\n",
    "            for item in playlists['playlists']['items']:\n",
    "                play_tracks = 0\n",
    "                print(f\"Playlist encontrada: {item['name']}\")\n",
    "                all_playlists.append(item)\n",
    "                # Obtendo as tracks da playlist\n",
    "                play_id = item['id']\n",
    "                print(f\"Obtendo m√∫sicas da playlist: {play_id}\")\n",
    "                tracks = get_playlist_tracks(play_id, market = market)\n",
    "                # Salvando o objeto de tracks em um arquivo parquet\n",
    "                df = pd.DataFrame(tracks)\n",
    "                # Convertendo o DataFrame para um Arrow Table\n",
    "                table = pa.Table.from_pandas(df)\n",
    "                # Salvando o arquivo parquet\n",
    "                pq.write_table(table, f'tracks_{play_id}.parquet')\n",
    "                # Incrementando o contador de m√∫sicas\n",
    "                play_tracks += len(tracks)\n",
    "                print(f\"M√∫sicas encontradas: {play_tracks}\")\n",
    "                print(\"-------------------------------------------------------\")\n",
    "                all_tracks += play_tracks\n",
    "        except Exception as e:\n",
    "            print(\"Erro ao obter playlists: \", e)\n",
    "            continue\n",
    "\n",
    "    # Salvando o objeto de playlists em um arquivo parquet\n",
    "    df = pd.DataFrame(all_playlists)\n",
    "    # Convertendo o DataFrame para um Arrow Table\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    # Salvando o arquivo parquet\n",
    "    pq.write_table(table, f'playlists_{query}.parquet')\n",
    "    print(f\"Playlists encontradas: {len(all_playlists)}\")\n",
    "    print(f\"Musicas encontradas: {all_tracks}\")\n",
    "    return all_playlists\n",
    "\n",
    "# Fun√ß√£o para obter todas as m√∫sicas de uma playlist\n",
    "def get_playlist_tracks(playlist_id, limit = 100, market = 'BR'):\n",
    "    all_tracks = []\n",
    "    try:\n",
    "        results = sp.playlist_tracks(playlist_id, limit = limit, market = market)\n",
    "        while results['next']:\n",
    "            results = sp.next(results)\n",
    "            all_tracks.extend(results['items'])\n",
    "    except Exception as e:\n",
    "        print(\"Erro ao obter m√∫sicas da playlist: \", e)\n",
    "    return all_tracks\n",
    "\n",
    "# Obtendo as n*offset playlists retornadas pela fun√ß√£o get_playlists\n",
    "top_playlists = get_playlists(query = 'underground carioca', n = 1, offset = 5, market = 'BR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7312/631843341.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
      "/tmp/ipykernel_7312/631843341.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
      "/tmp/ipykernel_7312/631843341.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
      "/tmp/ipykernel_7312/631843341.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
      "/tmp/ipykernel_7312/631843341.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
      "/tmp/ipykernel_7312/631843341.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
      "/tmp/ipykernel_7312/631843341.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
      "/tmp/ipykernel_7312/631843341.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
      "/tmp/ipykernel_7312/631843341.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Unificar todos os arquivos parquet de tracks do diret√≥rio\n",
    "\n",
    "# Lista todos os arquivos parquet do diret√≥rio\n",
    "files = glob.glob('tracks_*.parquet')\n",
    "\n",
    "for file in files:\n",
    "    table = pq.read_table(file)\n",
    "    df = table.to_pandas()\n",
    "\n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    for row in df.iterrows():\n",
    "        if not row[1]['track']:\n",
    "            continue\n",
    "        # Converte cada linha em uma entrada na tabela com colunas\n",
    "        new_row = {\n",
    "            'id': row[1]['track']['id'] if row[1]['track']['id'] else None,\n",
    "            'nome': row[1]['track']['name'] if row[1]['track']['name'] else None,\n",
    "            'popularidade': row[1]['track']['popularity'] if row[1]['track']['popularity'] else None,\n",
    "            'track': row[1]['track']['track'] if row[1]['track']['track'] else None,\n",
    "            'num_track': row[1]['track']['track_number'] if row[1]['track']['track_number'] else None,\n",
    "            'tipo': row[1]['track']['type'] if row[1]['track']['type'] else None,\n",
    "            'album': row[1]['track']['album']['name'] if row[1]['track']['album']['name'] else None,\n",
    "            'artistas': [{'nome': artist['name'], 'id': artist['id']}\n",
    "                if artist and artist['name'] and artist['id'] else None\n",
    "                for artist in row[1]['track']['artists']],\n",
    "            'num_disc': row[1]['track']['disc_number'] if row[1]['track']['disc_number'] else None,\n",
    "            'duracao': row[1]['track']['duration_ms'] if row[1]['track']['duration_ms'] else None,\n",
    "            'explicita': row[1]['track']['explicit'] if row[1]['track']['explicit'] else None,\n",
    "            'ids_externos': row[1]['track']['external_ids'] if row[1]['track']['external_ids'] else None,\n",
    "            'urls_externas': row[1]['track']['external_urls'] if row[1]['track']['external_urls'] else None,\n",
    "            'href': row[1]['track']['href'] if row[1]['track']['href'] else None,\n",
    "            'local': row[1]['track']['is_local'] if row[1]['track']['is_local'] else None,\n",
    "            'tocavel': row[1]['track']['is_playable'] if row[1]['track']['is_playable'] else None,\n",
    "            'preview_url': row[1]['track']['preview_url'] if row[1]['track']['preview_url'] else None,\n",
    "            'uri': row[1]['track']['uri'] if row[1]['track']['uri'] else None,\n",
    "        }\n",
    "        new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    # Exportando o DataFrame para um novo arquivo parquet\n",
    "    table = pa.Table.from_pandas(new_df)\n",
    "    pq.write_table(table, 'pre_proc_' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('playlists_*.parquet')\n",
    "\n",
    "for file in files:\n",
    "    table = pq.read_table(f'playlists_artistas independentes brasil 2023.parquet')\n",
    "    df = table.to_pandas()\n",
    "\n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    for row in df.iterrows():\n",
    "        # Converte cada linha em uma entrada na tabela com colunas\n",
    "        # Nome da Playlist, Descri√ß√£o, Link Externo, Propriet√°rio, Total de Faixas\n",
    "        new_row = {\n",
    "            'id': row[1]['id'],\n",
    "            'nome': row[1]['name'],\n",
    "            'descricao': row[1]['description'],\n",
    "            'link': row[1]['external_urls']['spotify'],\n",
    "            'proprietario': row[1]['owner']['display_name'],\n",
    "            'n_faixas': row[1]['tracks']['total']\n",
    "        }\n",
    "        new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    # Exportando o DataFrame para um novo arquivo parquet\n",
    "    table = pa.Table.from_pandas(new_df)\n",
    "    pq.write_table(table, 'pre_proc_' + file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
