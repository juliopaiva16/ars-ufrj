{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzZIV7YV2cBR"
      },
      "source": [
        "### Instalação dos pacotes necessários\n",
        "\n",
        "Pandas: Biblioteca para manipulação e análise de dados\n",
        "PyArrow: Biblioteca para leitura e escrita de arquivos parquet\n",
        "Spotipy: Biblioteca para acesso a API do Spotify\n",
        "\n",
        "Use o comando abaixo para instalar os pacotes necessários:\n",
        "```bash\n",
        "$ pip install pandas pyarrow spotipy\n",
        "```\n",
        "\n",
        "Ou instale as dependências diretamente do arquivo `requirements.txt`:\n",
        "```bash\n",
        "$ pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "### Configuração da API do Spotify com um .env\n",
        "\n",
        "Para acessar a API do Spotify é necessário criar um aplicativo no [Spotify for Developers](https://developer.spotify.com/dashboard/applications) e obter as credenciais de acesso.\n",
        "\n",
        "Crie um arquivo `.env` na raiz do projeto e adicione as seguintes variáveis de ambiente:\n",
        "```bash\n",
        "SPOTIPY_CLIENT_ID=seu_client_id\n",
        "SPOTIPY_CLIENT_SECRET=sua_client_secret\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "TywBUQWq2cBU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "import os\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "mqJIUXJ72cBW"
      },
      "outputs": [],
      "source": [
        "env_vars = {}\n",
        "\n",
        "# Le o arquivo .env\n",
        "with open('.env') as f:\n",
        "    env_vars = dict(\n",
        "        tuple(line.replace('\"', '').replace(\"'\", '').strip().split('=', 1)) for line in f\n",
        "    )\n",
        "\n",
        "# Cria o objeto de autenticação\n",
        "client_credentials_manager = SpotifyClientCredentials(\n",
        "    client_id=env_vars['SPOTIPY_CLIENT_ID'],\n",
        "    client_secret=env_vars['SPOTIPY_CLIENT_SECRET']\n",
        ")\n",
        "\n",
        "# Configurando as credenciais do cliente\n",
        "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "id": "d2dUMlKA2cBW"
      },
      "outputs": [],
      "source": [
        "# Obtém as playlists de um determinado termo de busca e salva em um arquivo\n",
        "# parquet\n",
        "def get_playlists(\n",
        "    query = '',\n",
        "    directory = '',\n",
        "    n = 1,\n",
        "    offset = 50,\n",
        "    market = 'BR',\n",
        "    verbose = False,\n",
        "):\n",
        "    print(f'{directory} - obtendo playlists...')\n",
        "    all_playlists = []\n",
        "    play_ids = []\n",
        "    for i in range(n):\n",
        "        try:\n",
        "            playlists = sp.search(\n",
        "                query,\n",
        "                limit=offset,\n",
        "                offset=i*offset,\n",
        "                type='playlist',\n",
        "                market = market,\n",
        "            )\n",
        "            # Printando o nome das playlists\n",
        "            for item in playlists['playlists']['items']:\n",
        "                play_tracks = 0\n",
        "                if verbose:\n",
        "                    print(f\"Playlist encontrada: {item['name']}\")\n",
        "                all_playlists.append(item)\n",
        "                play_ids.append(item['id'])\n",
        "        except Exception as e:\n",
        "            if 'http status: 404' in str(e):\n",
        "                print(\"Playlist não encontrada.\")\n",
        "                break\n",
        "            elif 'http status: 400' in str(e):\n",
        "                print(\n",
        "                    \"Erro 400: Provavelmente o offset é maior que o número \"\n",
        "                    \"de playlists disponíveis.\"\n",
        "                )\n",
        "                break\n",
        "            else:\n",
        "                print(\"Erro ao obter playlists: \", e)\n",
        "                continue\n",
        "    # Salvando o objeto de playlists em um arquivo parquet\n",
        "    df = pd.DataFrame(all_playlists)\n",
        "    # Convertendo o DataFrame para um Arrow Table\n",
        "    table = pa.Table.from_pandas(df)\n",
        "    # Salvando o arquivo parquet\n",
        "    pq.write_table(table, directory + '/playlists.parquet')\n",
        "    print(f'{directory} - playlists obtidas: {len(play_ids)}')\n",
        "    return play_ids\n",
        "\n",
        "# Função para obter todas as músicas de uma playlist\n",
        "def get_playlist_tracks(\n",
        "    play_id,\n",
        "    directory = '',\n",
        "    n = 1,\n",
        "    offset = 50,\n",
        "    market = 'BR',\n",
        "):\n",
        "    print(f\"{play_id} - obtendo músicas...\")\n",
        "    all_tracks = []\n",
        "    for i in range(n):\n",
        "        try:\n",
        "            results = sp.playlist_tracks(\n",
        "                play_id,\n",
        "                limit = offset,\n",
        "                offset=i*offset,\n",
        "                additional_types=('track'),\n",
        "            )\n",
        "            if not results['items']:\n",
        "                print(\"Playlist vazia.\")\n",
        "                break\n",
        "            all_tracks.extend(results['items'])\n",
        "        except Exception as e:\n",
        "            if 'http status: 404' in str(e):\n",
        "                print(\"Playlist não encontrada.\")\n",
        "                break\n",
        "            elif 'http status: 400' in str(e):\n",
        "                print(\n",
        "                    \"Erro 400: Provavelmente o offset é maior que o número \"\n",
        "                    \"de músicas disponíveis.\"\n",
        "                )\n",
        "                break\n",
        "            else:\n",
        "                print(\"Erro ao obter músicas da playlist: \", e)\n",
        "                continue\n",
        "    # Salvando o objeto de tracks em um arquivo parquet\n",
        "    df = pd.DataFrame(all_tracks)\n",
        "    # Convertendo o DataFrame para um Arrow Table\n",
        "    table = pa.Table.from_pandas(df)\n",
        "    # Salvando o arquivo parquet\n",
        "    pq.write_table(table, directory + f'/tracks_{play_id}.parquet')\n",
        "    print(f\"{play_id} - músicas obtidas: {len(all_tracks)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "id": "E-5nuZr52cBW"
      },
      "outputs": [],
      "source": [
        "# Unificar todos os arquivos parquet de tracks do diretório\n",
        "def unify_track_files(directory, filename = None):\n",
        "\n",
        "    # Lista todos os arquivos parquet do diretório\n",
        "    files = glob.glob(directory + '/tracks_*.parquet')\n",
        "\n",
        "    for file in files:\n",
        "        filename = file.split('/')[-1].replace('.parquet', '')\n",
        "\n",
        "        table = pq.read_table(file)\n",
        "        df = table.to_pandas()\n",
        "\n",
        "        new_df = pd.DataFrame()\n",
        "\n",
        "        for row in df.iterrows():\n",
        "            if not row[1]['track']:\n",
        "                continue\n",
        "            # Converte cada linha em uma entrada na tabela com colunas\n",
        "            new_row = {\n",
        "                'id': row[1]['track']['id'] if row[1]['track']['id'] else None,\n",
        "                'nome': row[1]['track']['name'] if row[1]['track']['name'] else None,\n",
        "                'popularidade': row[1]['track']['popularity'] if row[1]['track']['popularity'] else None,\n",
        "                'track': row[1]['track']['track'] if row[1]['track']['track'] else None,\n",
        "                'num_track': row[1]['track']['track_number'] if row[1]['track']['track_number'] else None,\n",
        "                'tipo': row[1]['track']['type'] if row[1]['track']['type'] else None,\n",
        "                'album': row[1]['track']['album']['name'] if row[1]['track']['album']['name'] else None,\n",
        "                'artistas': [{'nome': artist['name'], 'id': artist['id']}\n",
        "                    if artist and artist['name'] and artist['id'] else None\n",
        "                    for artist in row[1]['track']['artists']],\n",
        "                'num_disc': row[1]['track']['disc_number'] if row[1]['track']['disc_number'] else None,\n",
        "                'duracao': row[1]['track']['duration_ms'] if row[1]['track']['duration_ms'] else None,\n",
        "                'explicita': row[1]['track']['explicit'] if row[1]['track']['explicit'] else None,\n",
        "                'ids_externos': row[1]['track']['external_ids'] if row[1]['track']['external_ids'] else None,\n",
        "                'urls_externas': row[1]['track']['external_urls'] if row[1]['track']['external_urls'] else None,\n",
        "                'href': row[1]['track']['href'] if row[1]['track']['href'] else None,\n",
        "                'local': row[1]['track']['is_local'] if row[1]['track']['is_local'] else None,\n",
        "                'preview_url': row[1]['track']['preview_url'] if row[1]['track']['preview_url'] else None,\n",
        "                'uri': row[1]['track']['uri'] if row[1]['track']['uri'] else None,\n",
        "            }\n",
        "            new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "        # Exportando o DataFrame para um novo arquivo parquet\n",
        "        table = pa.Table.from_pandas(new_df)\n",
        "        pq.write_table(table, directory + '/pre_proc_' + filename + '.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "id": "Ku1p51qm2cBX"
      },
      "outputs": [],
      "source": [
        "def unify_playlist_files(directory):\n",
        "    table = pq.read_table(directory + '/playlists.parquet')\n",
        "    df = table.to_pandas()\n",
        "\n",
        "    new_df = pd.DataFrame()\n",
        "\n",
        "    for row in df.iterrows():\n",
        "        # Converte cada linha em uma entrada na tabela com colunas\n",
        "        # Nome da Playlist, Descrição, Link Externo, Proprietário, Total de Faixas\n",
        "        new_row = {\n",
        "            'id': row[1]['id']\n",
        "                if row[1]['id'] else None,\n",
        "            'nome': row[1]['name']\n",
        "                if row[1]['name'] else None,\n",
        "            'descricao': row[1]['description']\n",
        "                if row[1]['description'] else None,\n",
        "            'link': row[1]['external_urls']['spotify']\n",
        "                if row[1]['external_urls']['spotify'] else None,\n",
        "            'proprietario': row[1]['owner']['display_name']\n",
        "                if row[1]['owner']['display_name'] else None,\n",
        "            'n_faixas': row[1]['tracks']['total']\n",
        "                if row[1]['tracks']['total'] else None,\n",
        "        }\n",
        "        new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "    # Exportando o DataFrame para um novo arquivo parquet\n",
        "    table = pa.Table.from_pandas(new_df)\n",
        "    pq.write_table(table, directory + '/pre_proc.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG55V32T2cBX"
      },
      "source": [
        "### Execução do script\n",
        "\n",
        "Usando a lista de queries fornecida, o script irá buscar playlists no Spotify e salvar os dados em um arquivo parquet\n",
        "relacionado a cada query.\n",
        "\n",
        "Além disso, para cada playlist encontrada, o script irá buscar as músicas e salvar os dados em um arquivo parquet\n",
        "relacionado a cada playlist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CUik8sZ2cBX",
        "outputId": "b630d3a6-3fa7-421f-868d-795605c66a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "queries/rock_independente_brasil - obtendo playlists...\n",
            "queries/rock_independente_brasil - playlists obtidas: 499\n",
            "0WMhbcomnJeIM1NCzGpIPJ - obtendo músicas...\n",
            "Playlist vazia.\n",
            "0WMhbcomnJeIM1NCzGpIPJ - músicas obtidas: 22\n",
            "37i9dQZF1DWUjoOWKKJzAy - obtendo músicas...\n",
            "Playlist vazia.\n",
            "37i9dQZF1DWUjoOWKKJzAy - músicas obtidas: 60\n",
            "5UgB6DzOWAIVv94iGmBTex - obtendo músicas...\n",
            "Playlist vazia.\n",
            "5UgB6DzOWAIVv94iGmBTex - músicas obtidas: 27\n",
            "6utijPXudrtHFrTubS1mes - obtendo músicas...\n",
            "Playlist vazia.\n",
            "6utijPXudrtHFrTubS1mes - músicas obtidas: 190\n",
            "42Gj0MPuyT5R3EjZIx3S1p - obtendo músicas...\n",
            "Playlist vazia.\n",
            "42Gj0MPuyT5R3EjZIx3S1p - músicas obtidas: 196\n",
            "2bq1zwnjpuQnrYuQLxwSZq - obtendo músicas...\n",
            "Playlist vazia.\n",
            "2bq1zwnjpuQnrYuQLxwSZq - músicas obtidas: 331\n",
            "3O0kKyRVt6TxYBTU4EYikO - obtendo músicas...\n",
            "Playlist vazia.\n",
            "3O0kKyRVt6TxYBTU4EYikO - músicas obtidas: 143\n",
            "0R4OqX1MF6JrUiQhbrDJ6I - obtendo músicas...\n",
            "Playlist vazia.\n",
            "0R4OqX1MF6JrUiQhbrDJ6I - músicas obtidas: 12\n",
            "6JaQHAaEKZTk6zW8n5g4fj - obtendo músicas...\n",
            "Playlist vazia.\n",
            "6JaQHAaEKZTk6zW8n5g4fj - músicas obtidas: 134\n",
            "4s3CdyKekT0UicLh2zG6X6 - obtendo músicas...\n",
            "Playlist vazia.\n",
            "4s3CdyKekT0UicLh2zG6X6 - músicas obtidas: 152\n",
            "7Lq0b9ma5caiUq1EiEMP6K - obtendo músicas...\n",
            "Playlist vazia.\n",
            "7Lq0b9ma5caiUq1EiEMP6K - músicas obtidas: 75\n",
            "5YBK1H4AT7ZEgIzs8LlEon - obtendo músicas...\n",
            "Playlist vazia.\n",
            "5YBK1H4AT7ZEgIzs8LlEon - músicas obtidas: 26\n",
            "4o7yGyruMGx41nMVm5hJS6 - obtendo músicas...\n",
            "Playlist vazia.\n",
            "4o7yGyruMGx41nMVm5hJS6 - músicas obtidas: 111\n",
            "4o6SZiRiIDWxyyUSIYt3ns - obtendo músicas...\n",
            "Playlist vazia.\n",
            "4o6SZiRiIDWxyyUSIYt3ns - músicas obtidas: 35\n",
            "5Qxsrhxh0wNAL7elB9Pd8W - obtendo músicas...\n",
            "Playlist vazia.\n",
            "5Qxsrhxh0wNAL7elB9Pd8W - músicas obtidas: 140\n",
            "3k3TdY71hvXFfnwDjh5UAi - obtendo músicas...\n",
            "Playlist vazia.\n",
            "3k3TdY71hvXFfnwDjh5UAi - músicas obtidas: 62\n",
            "19StETfvVK4stuLhqmh1aq - obtendo músicas...\n",
            "Playlist vazia.\n",
            "19StETfvVK4stuLhqmh1aq - músicas obtidas: 105\n",
            "12VsyK5QsPH9P0wYCLeULR - obtendo músicas...\n",
            "Playlist vazia.\n",
            "12VsyK5QsPH9P0wYCLeULR - músicas obtidas: 154\n",
            "7tJSlaad9s6aiGloaqRJML - obtendo músicas...\n",
            "Playlist vazia.\n",
            "7tJSlaad9s6aiGloaqRJML - músicas obtidas: 95\n",
            "70K1313F9BhzyvJvyQn8yH - obtendo músicas...\n",
            "Playlist vazia.\n",
            "70K1313F9BhzyvJvyQn8yH - músicas obtidas: 45\n",
            "0ZdHI5yqWcX66Fk5D05zpP - obtendo músicas...\n",
            "Playlist vazia.\n",
            "0ZdHI5yqWcX66Fk5D05zpP - músicas obtidas: 70\n",
            "2V6u4zLYDiGxVWxSlce68Y - obtendo músicas...\n",
            "Playlist vazia.\n",
            "2V6u4zLYDiGxVWxSlce68Y - músicas obtidas: 124\n",
            "37i9dQZF1DX2nd8BSnFnzT - obtendo músicas...\n"
          ]
        }
      ],
      "source": [
        "estilo_1 = 'rock'\n",
        "estilo_2 = 'pop'\n",
        "\n",
        "# Lista de queries para buscar playlists\n",
        "# Essa lista vai definir quais playlists serão buscadas\n",
        "# e vai dividir as rodadas em pastas diferentes\n",
        "query_list = [\n",
        "   estilo_1 + ' independente brasil',\n",
        "   estilo_1 + ' indie brasil',\n",
        "   estilo_1 + ' alternativo brasil',\n",
        "   estilo_1 + ' paradas brasil',\n",
        "   estilo_1 + ' top hits brasil',\n",
        "   estilo_1 + ' lançamentos brasil',\n",
        "   estilo_2 + ' independente brasil',\n",
        "   estilo_2 + ' indie brasil',\n",
        "   estilo_2 + ' alternativo brasil',\n",
        "   estilo_2 + ' paradas brasil',\n",
        "   estilo_2 + ' top hits brasil',\n",
        "   estilo_2 + ' lançamentos brasil',\n",
        "]\n",
        "\n",
        "for query in query_list:\n",
        "    # Criar a pasta para a query\n",
        "    directory = 'queries/' + query.replace(' ', '_')\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    # Obter as playlists\n",
        "    playlists = get_playlists(\n",
        "        query, directory = directory,\n",
        "        n = 10, offset = 50,\n",
        "        market = 'BR'\n",
        "    )\n",
        "    # Obter as músicas das playlists\n",
        "    for play_id in playlists:\n",
        "        get_playlist_tracks(\n",
        "            play_id,\n",
        "            directory = directory,\n",
        "            n = 10, offset = 50,\n",
        "            market = 'BR'\n",
        "        )\n",
        "    # Unificar os arquivos parquet de tracks e playlists\n",
        "    unify_playlist_files(directory)\n",
        "    unify_track_files(directory)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "trab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
